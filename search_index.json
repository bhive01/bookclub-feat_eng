[["index.html", "Feature Engineering and Selection Book Club Welcome", " Feature Engineering and Selection Book Club The R4DS Online Learning Community 2022-08-19 Welcome Welcome to the bookclub! This is a companion for the book Feature Engineering and Selection: A Practical Approach for Predictive Models by Max Kuhn and Kjell Johnson (Chapman and Hall/CRC, copyright August 2, 2019, 9781138079229). This companion is available at r4ds.io/feat_eng. This website is being developed by the R4DS Online Learning Community. Follow along, and join the community to participate. This companion follows the R4DS Online Learning Community Code of Conduct. "],["book-club-meetings.html", "Book club meetings", " Book club meetings Each week, a volunteer will present a chapter from the book (or part of a chapter). This is the best way to learn the material. Presentations will usually consist of a review of the material, a discussion, and/or a demonstration of the principles presented in that chapter. More information about how to present is available in the github repo. Presentations will be recorded, and will be available on the R4DS Online Learning Community YouTube Channel. "],["pace.html", "Pace", " Pace We’ll try to cover 1 chapter/week, but… …It’s ok to split chapters when they feel like too much. We will try to meet every week, but will likely take some breaks for holidays, etc. "],["introduction.html", "Chapter 1 Introduction", " Chapter 1 Introduction Learning objectives: Recognize the structure of the book Establish base lines for good practice Define feature engineering "],["structure-of-the-book.html", "1.1 Structure of the book", " 1.1 Structure of the book The book is divided into two main parts: Feature engineering (techniques for augmenting predictors - chapters 2-9) Predicting risk of Ischemic Review of the PMP (predictive modeling process) Exploratory visualization Encoding categorical predictors Engineering numeric predictors Detecting interaction effects Handling missing data Working with profile data (time series analysis) Feature selection (methods for filtering the enhanced predictors - chapters 10-12) Overview Greedy search methods (simple filters and eliminations) Golbal search methods (predictor space investigations) "],["good-practice-guidelines.html", "1.2 Good Practice guidelines", " 1.2 Good Practice guidelines There are some vital steps to take to modeling: knowledge of the process to model collect appropriate data understand variation in the response select relevant predictors utilize a range of models All of these are not enough when model lacks on performance. The answer might be the in the way the predictors are presented to the model. 1.2.1 What is feature engineering “…best re-representation of the predictors to improve model performance.” (ct. Preface) What are the possible ways to acheive a better performance? transform the predictors with special functions (log/exp) add an interaction term (prod/ratio) add a functional transformation (splines/poly) add a re-representation of the predictors (mean/med/standardz) imputing missing values (knn/bagging) Disclaimer: Risk of Overfitting! 1.2.2 Nature of modeling The estimation of uncertainty/noise is another very important step to take. “If a model is only 50% accurate should it be used to make inferences or predictions?” The trade-off between accuracy and interpretability is important, a neural network model might be less explicable but can provide a higher level of accuracy. Feature engineering is a matter of choice in finding the most suitable variable transformation for the best performance. More considerations about bad model reactions to: multicollinarity or correlation between predictors missing values irrelevant predictors "],["a-model-with-two-predictors.html", "1.3 A model with two predictors", " 1.3 A model with two predictors data(segmentationData) This example uses segmentationData. Data originates from an experiment from Hill et al. (2007), a study on “Impact of Image Segmentation on High-Content Screening Data Quality for SK-BR-3 Cells.” BMC Bioinformatics. The data set includes a Case vector containing Train and Test variables, with a total of 61 different vectors, about cellular structures and morphology. Selected for this first example are two predictors: EqSphereAreaCh1 and PerimCh1. The objective is to predict shape parameters of poorly-segmented (PS) and well-segmented (WS) cells from the Class variable. This is the full list of variables in the set. ## [1] &quot;Cell&quot; &quot;Case&quot; ## [3] &quot;Class&quot; &quot;AngleCh1&quot; ## [5] &quot;AreaCh1&quot; &quot;AvgIntenCh1&quot; ## [7] &quot;AvgIntenCh2&quot; &quot;AvgIntenCh3&quot; ## [9] &quot;AvgIntenCh4&quot; &quot;ConvexHullAreaRatioCh1&quot; ## [11] &quot;ConvexHullPerimRatioCh1&quot; &quot;DiffIntenDensityCh1&quot; ## [13] &quot;DiffIntenDensityCh3&quot; &quot;DiffIntenDensityCh4&quot; ## [15] &quot;EntropyIntenCh1&quot; &quot;EntropyIntenCh3&quot; ## [17] &quot;EntropyIntenCh4&quot; &quot;EqCircDiamCh1&quot; ## [19] &quot;EqEllipseLWRCh1&quot; &quot;EqEllipseOblateVolCh1&quot; ## [21] &quot;EqEllipseProlateVolCh1&quot; &quot;EqSphereAreaCh1&quot; ## [23] &quot;EqSphereVolCh1&quot; &quot;FiberAlign2Ch3&quot; ## [25] &quot;FiberAlign2Ch4&quot; &quot;FiberLengthCh1&quot; ## [27] &quot;FiberWidthCh1&quot; &quot;IntenCoocASMCh3&quot; ## [29] &quot;IntenCoocASMCh4&quot; &quot;IntenCoocContrastCh3&quot; ## [31] &quot;IntenCoocContrastCh4&quot; &quot;IntenCoocEntropyCh3&quot; ## [33] &quot;IntenCoocEntropyCh4&quot; &quot;IntenCoocMaxCh3&quot; ## [35] &quot;IntenCoocMaxCh4&quot; &quot;KurtIntenCh1&quot; ## [37] &quot;KurtIntenCh3&quot; &quot;KurtIntenCh4&quot; ## [39] &quot;LengthCh1&quot; &quot;NeighborAvgDistCh1&quot; ## [41] &quot;NeighborMinDistCh1&quot; &quot;NeighborVarDistCh1&quot; ## [43] &quot;PerimCh1&quot; &quot;ShapeBFRCh1&quot; ## [45] &quot;ShapeLWRCh1&quot; &quot;ShapeP2ACh1&quot; ## [47] &quot;SkewIntenCh1&quot; &quot;SkewIntenCh3&quot; ## [49] &quot;SkewIntenCh4&quot; &quot;SpotFiberCountCh3&quot; ## [51] &quot;SpotFiberCountCh4&quot; &quot;TotalIntenCh1&quot; ## [53] &quot;TotalIntenCh2&quot; &quot;TotalIntenCh3&quot; ## [55] &quot;TotalIntenCh4&quot; &quot;VarIntenCh1&quot; ## [57] &quot;VarIntenCh3&quot; &quot;VarIntenCh4&quot; ## [59] &quot;WidthCh1&quot; &quot;XCentroid&quot; ## [61] &quot;YCentroid&quot; ## [1] 2019 61 Parsimony: ## Class Area Perimeter ## 1 PS 3278.726 154.89876 ## 2 WS 1727.410 84.56460 ## 3 PS 1194.932 101.09107 ## 4 WS 1027.222 68.71062 ## 5 PS 1035.608 73.40559 ## 6 PS 1433.918 79.47569 The dataset is already split between training and test sets, all that is to be added is cross-validation on the training set. set.seed(2222) folds &lt;- vfold_cv(train, v = 10) A first visualization of the relationship between the two predictors. Check for Class imbalance of the response variable This would be the first level transformation of the response, this type of transformation is considered a structural transformation, we will see more about it later in the book. PS WS tb_class 636.00 373.00 pr_class 0.63 0.37 up_samp_ws &lt;- pr_class[2] Recipes library(themis) log_rec_natural_units &lt;- recipe(Class ~ Area + Perimeter, data = train) %&gt;% step_upsample(Class, over_ratio = up_samp_ws) log_rec_inverse_units &lt;- recipe(Class ~ Area + Perimeter, data = train) %&gt;% step_upsample(Class, over_ratio = up_samp_ws) %&gt;% step_BoxCox(all_numeric()) Workflow logistic_reg_glm_spec &lt;- logistic_reg() %&gt;% set_engine(&#39;glm&#39;) log_wfl_natural_units &lt;- workflow() %&gt;% add_model(logistic_reg_glm_spec) %&gt;% add_recipe(log_rec_natural_units) log_fit_natural_units &lt;- log_wfl_natural_units %&gt;% fit(train) log_fit_natural_units %&gt;% extract_fit_parsnip() %&gt;% tidy() # A tibble: 3 × 5 term estimate std.error statistic p.value &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 (Intercept) 1.58 0.248 6.36 1.99e-10 2 Area 0.00301 0.000281 10.7 8.95e-27 3 Perimeter -0.0682 0.00604 -11.3 1.47e-29 Prediction with_pred_natural_units &lt;- log_fit_natural_units %&gt;% augment(test) with_pred_natural_units %&gt;% head # A tibble: 6 × 6 Class Area Perimeter .pred_class .pred_PS .pred_WS &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; 1 PS 742. 68.8 PS 0.705 0.295 2 PS 1140. 86.5 PS 0.707 0.293 3 WS 692. 49.5 WS 0.429 0.571 4 WS 709. 50.4 WS 0.431 0.569 5 PS 1006. 89.9 PS 0.820 0.180 6 WS 1983. 112. PS 0.516 0.484 Confusion Matrics Roc Curve with_pred_natural_units %&gt;% roc_curve(Class,.pred_PS) %&gt;% mutate(Format = &quot;Natural Units&quot;) %&gt;% ggplot(aes(1 - specificity, sensitivity))+ geom_line(aes(color = .threshold), size = 1)+ geom_abline(linetype = &quot;dashed&quot;, size = 1, color = &quot;gray&quot;) + scale_colour_continuous()+ theme_fivethirtyeight() + theme(axis.title = element_text()) Workflow set Let’s compare the two transformations with a workflow_set(): full_workflow &lt;- workflow_set( models = list(logitstic = logistic_reg_glm_spec), preproc = list(natural_units = log_rec_natural_units, inverse_units = log_rec_inverse_units)) system.time( grid_results &lt;- full_workflow %&gt;% workflow_map( seed = 1503, resamples = folds, grid = 25, control = control_grid( save_pred = TRUE, parallel_over = &quot;everything&quot;, save_workflow = TRUE), verbose = TRUE) ) user system elapsed 6.249 0.008 6.259 grid_results # A workflow set/tibble: 2 × 4 wflow_id info option result &lt;chr&gt; &lt;list&gt; &lt;list&gt; &lt;list&gt; 1 natural_units_logitstic &lt;tibble [1 × 4]&gt; &lt;opts[3]&gt; &lt;rsmp[+]&gt; 2 inverse_units_logitstic &lt;tibble [1 × 4]&gt; &lt;opts[3]&gt; &lt;rsmp[+]&gt; Roc curves for two different recipes roc &lt;- grid_results %&gt;% unnest(result) %&gt;% unnest(.predictions) %&gt;% select(wflow_id, .pred_PS, .pred_WS, .pred_class, Class) %&gt;% group_by(wflow_id) %&gt;% roc_curve(Class, .pred_PS) roc_curves &lt;- roc %&gt;% ggplot( aes(x = 1 - specificity, y = sensitivity, group = wflow_id, color = wflow_id) ) + geom_line(size = 0.5) + geom_abline(lty = 2, alpha = 0.5, color = &quot;gray50&quot;, size = 0.8)+ scale_color_tableau()+ theme_fivethirtyeight()+ theme(axis.title = element_text()) roc_curves "],["important-concepts.html", "1.4 Important concepts", " 1.4 Important concepts Overfitting Supervised and unsupervised Model bias and variance Experience and empirically driven modeling Generalizing the main boundaries, the risk of overfitting the model is always challenged by anomalous patterns new data can hide. 1.4.1 Acknowledge vulnerabilities To consider: small number of observations compared to the number of predictors low bias models can have a higher likelihood of overfitting supervised analysis can be used to detect predictors significance No free lunch therem (Wolpert, 1996) - knowledge is an important part of modeling variance-bias trade-off Low variance: linear/logistic regression and PLS High variance: trees, nearest neighbor, neural networks Bias: level of ability to closer estimation irrilevant predictors can causing excess model variation be data-driven rather than experience-driven big data does not mean better data unlabeled data can improve autoencoders modeling compensatory effect there may not be a unique set of predictors. Finally, one more important consideration is to consider Strategies for Supervised and Unsupervised feature selections. Supervised selection method can be divided into: wrapper methods, such as backwards and stepwise selection embedded methods, such as decision tree variable selection Unsupervised selection method variable encoding, such as dummy or indicator variables 1.4.2 The Modeling process Few steps summary: EDA summary and correlation model methods evaluation model tuning summary measures and EDA residual analysis/ check for systematic issues more feature engineering model selection final bake off prediction "],["predicting-ridership-on-chicago.html", "1.5 Predicting ridership on Chicago", " 1.5 Predicting ridership on Chicago This set will be widely used in the book to predict the number of people entering a train station daily. library(modeldata) modeldata::Chicago %&gt;% head ## # A tibble: 6 × 50 ## rider…¹ Austin Quinc…² Belmont Arche…³ Oak_P…⁴ Western Clark…⁵ Clinton Merch…⁶ ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 15.7 1.46 8.37 4.60 2.01 1.42 3.32 15.6 2.40 6.48 ## 2 15.8 1.50 8.35 4.72 2.09 1.43 3.34 15.7 2.40 6.48 ## 3 15.9 1.52 8.36 4.68 2.11 1.49 3.36 15.6 2.37 6.40 ## 4 15.9 1.49 7.85 4.77 2.17 1.44 3.36 15.7 2.42 6.49 ## 5 15.4 1.50 7.62 4.72 2.06 1.42 3.27 15.6 2.42 5.80 ## 6 2.42 0.693 0.911 2.27 0.624 0.426 1.11 2.41 0.814 0.858 ## # … with 40 more variables: Irving_Park &lt;dbl&gt;, Washington_Wells &lt;dbl&gt;, ## # Harlem &lt;dbl&gt;, Monroe &lt;dbl&gt;, Polk &lt;dbl&gt;, Ashland &lt;dbl&gt;, Kedzie &lt;dbl&gt;, ## # Addison &lt;dbl&gt;, Jefferson_Park &lt;dbl&gt;, Montrose &lt;dbl&gt;, California &lt;dbl&gt;, ## # temp_min &lt;dbl&gt;, temp &lt;dbl&gt;, temp_max &lt;dbl&gt;, temp_change &lt;dbl&gt;, dew &lt;dbl&gt;, ## # humidity &lt;dbl&gt;, pressure &lt;dbl&gt;, pressure_change &lt;dbl&gt;, wind &lt;dbl&gt;, ## # wind_max &lt;dbl&gt;, gust &lt;dbl&gt;, gust_max &lt;dbl&gt;, percip &lt;dbl&gt;, percip_max &lt;dbl&gt;, ## # weather_rain &lt;dbl&gt;, weather_snow &lt;dbl&gt;, weather_cloud &lt;dbl&gt;, … 1.5.1 Extra Resources Cooking Your Data with Recipes Here is a nice example on how to Compute a sliding mean by Julia Silge caret-vs-tidymodels tidymodels-or-caret-how-they-compare "],["meeting-videos.html", "1.6 Meeting Videos", " 1.6 Meeting Videos 1.6.1 Cohort 1 Meeting chat log LOG "],["illustrative-example-predicting-risk-of-ischemic-stroke.html", "Chapter 2 Illustrative Example: Predicting Risk of Ischemic Stroke", " Chapter 2 Illustrative Example: Predicting Risk of Ischemic Stroke Learning objectives: THESE ARE NICE TO HAVE BUT NOT ABSOLUTELY NECESSARY "],["slide-1.html", "2.1 SLIDE 1", " 2.1 SLIDE 1 ADD SLIDES AS SECTIONS (##). TRY TO KEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF. "],["meeting-videos-1.html", "2.2 Meeting Videos", " 2.2 Meeting Videos 2.2.1 Cohort 1 Meeting chat log LOG "],["a-review-of-the-predictive-modeling-process.html", "Chapter 3 A Review of the Predictive Modeling Process", " Chapter 3 A Review of the Predictive Modeling Process Learning objectives: THESE ARE NICE TO HAVE BUT NOT ABSOLUTELY NECESSARY "],["slide-1-1.html", "3.1 SLIDE 1", " 3.1 SLIDE 1 ADD SLIDES AS SECTIONS (##). TRY TO KEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF. "],["meeting-videos-2.html", "3.2 Meeting Videos", " 3.2 Meeting Videos 3.2.1 Cohort 1 Meeting chat log LOG "],["exploratory-visualizations.html", "Chapter 4 Exploratory Visualizations", " Chapter 4 Exploratory Visualizations Learning objectives: THESE ARE NICE TO HAVE BUT NOT ABSOLUTELY NECESSARY "],["slide-1-2.html", "4.1 SLIDE 1", " 4.1 SLIDE 1 ADD SLIDES AS SECTIONS (##). TRY TO KEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF. "],["meeting-videos-3.html", "4.2 Meeting Videos", " 4.2 Meeting Videos 4.2.1 Cohort 1 Meeting chat log LOG "],["encoding-categorical-predictors.html", "Chapter 5 Encoding Categorical Predictors", " Chapter 5 Encoding Categorical Predictors Learning objectives: THESE ARE NICE TO HAVE BUT NOT ABSOLUTELY NECESSARY "],["slide-1-3.html", "5.1 SLIDE 1", " 5.1 SLIDE 1 ADD SLIDES AS SECTIONS (##). TRY TO KEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF. "],["meeting-videos-4.html", "5.2 Meeting Videos", " 5.2 Meeting Videos 5.2.1 Cohort 1 Meeting chat log LOG "],["engineering-numeric-predictors.html", "Chapter 6 Engineering Numeric Predictors", " Chapter 6 Engineering Numeric Predictors Learning objectives: THESE ARE NICE TO HAVE BUT NOT ABSOLUTELY NECESSARY "],["slide-1-4.html", "6.1 SLIDE 1", " 6.1 SLIDE 1 ADD SLIDES AS SECTIONS (##). TRY TO KEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF. "],["meeting-videos-5.html", "6.2 Meeting Videos", " 6.2 Meeting Videos 6.2.1 Cohort 1 Meeting chat log LOG "],["detecting-interaction-effects.html", "Chapter 7 Detecting Interaction Effects", " Chapter 7 Detecting Interaction Effects Learning objectives: THESE ARE NICE TO HAVE BUT NOT ABSOLUTELY NECESSARY "],["slide-1-5.html", "7.1 SLIDE 1", " 7.1 SLIDE 1 ADD SLIDES AS SECTIONS (##). TRY TO KEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF. "],["meeting-videos-6.html", "7.2 Meeting Videos", " 7.2 Meeting Videos 7.2.1 Cohort 1 Meeting chat log LOG "],["handling-missing-data.html", "Chapter 8 Handling Missing Data", " Chapter 8 Handling Missing Data Learning objectives: THESE ARE NICE TO HAVE BUT NOT ABSOLUTELY NECESSARY "],["slide-1-6.html", "8.1 SLIDE 1", " 8.1 SLIDE 1 ADD SLIDES AS SECTIONS (##). TRY TO KEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF. "],["meeting-videos-7.html", "8.2 Meeting Videos", " 8.2 Meeting Videos 8.2.1 Cohort 1 Meeting chat log LOG "],["working-with-profile-data.html", "Chapter 9 Working with Profile Data", " Chapter 9 Working with Profile Data Learning objectives: THESE ARE NICE TO HAVE BUT NOT ABSOLUTELY NECESSARY "],["slide-1-7.html", "9.1 SLIDE 1", " 9.1 SLIDE 1 ADD SLIDES AS SECTIONS (##). TRY TO KEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF. "],["meeting-videos-8.html", "9.2 Meeting Videos", " 9.2 Meeting Videos 9.2.1 Cohort 1 Meeting chat log LOG "],["feature-selection-overview.html", "Chapter 10 Feature Selection Overview", " Chapter 10 Feature Selection Overview Learning objectives: THESE ARE NICE TO HAVE BUT NOT ABSOLUTELY NECESSARY "],["slide-1-8.html", "10.1 SLIDE 1", " 10.1 SLIDE 1 ADD SLIDES AS SECTIONS (##). TRY TO KEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF. "],["meeting-videos-9.html", "10.2 Meeting Videos", " 10.2 Meeting Videos 10.2.1 Cohort 1 Meeting chat log LOG "],["greedy-search-methods.html", "Chapter 11 Greedy Search Methods", " Chapter 11 Greedy Search Methods Learning objectives: THESE ARE NICE TO HAVE BUT NOT ABSOLUTELY NECESSARY "],["slide-1-9.html", "11.1 SLIDE 1", " 11.1 SLIDE 1 ADD SLIDES AS SECTIONS (##). TRY TO KEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF. "],["meeting-videos-10.html", "11.2 Meeting Videos", " 11.2 Meeting Videos 11.2.1 Cohort 1 Meeting chat log LOG "],["global-search-methods.html", "Chapter 12 Global Search Methods", " Chapter 12 Global Search Methods Learning objectives: THESE ARE NICE TO HAVE BUT NOT ABSOLUTELY NECESSARY "],["slide-1-10.html", "12.1 SLIDE 1", " 12.1 SLIDE 1 ADD SLIDES AS SECTIONS (##). TRY TO KEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF. "],["meeting-videos-11.html", "12.2 Meeting Videos", " 12.2 Meeting Videos 12.2.1 Cohort 1 Meeting chat log LOG "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
